% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_model.r
\name{train.model}
\alias{train.model}
\title{Model training}
\usage{
train.model(siamcat,
method = c("lasso","enet","ridge","lasso_ll", "ridge_ll", "randomForest"),
stratify = TRUE, modsel.crit = list("auc"), min.nonzero.coeff = 1,
param.set = NULL, perform.fs = FALSE, 
param.fs = list(thres.fs = 100, method.fs = "AUC"), verbose = 1)
}
\arguments{
\item{siamcat}{object of class \link{siamcat-class}}

\item{method}{string, specifies the type of model to be trained, may be one
of these: \code{c('lasso', 'enet', 'ridge', 'lasso_ll', 'ridge_ll',
'randomForest')}}

\item{stratify}{boolean, should the folds in the internal cross-validation be
stratified?, defaults to \code{TRUE}}

\item{modsel.crit}{list, specifies the model selection criterion during
internal cross-validation, may contain these: \code{c('auc', 'f1',
'acc', 'pr')}, defaults to \code{list('auc')}}

\item{min.nonzero.coeff}{integer number of minimum nonzero coefficients that
should be present in the model (only for \code{'lasso'},
\code{'ridge'}, and \code{'enet'}, defaults to \code{1}}

\item{param.set}{a list of extra parameters for mlr run, may contain:
\itemize{
\item \code{cost} - for lasso_ll and ridge_ll
\item \code{alpha} for enet
\item \code{ntree} and \code{mtry} for RandomForrest.
} Defaults to \code{NULL}}

\item{perform.fs}{boolean, should feature selection be performed?
Defaults to \code{FALSE}}

\item{param.fs}{a list of parameters for the feature selection, must contain:
\itemize{
\item \code{thres.fs} - threshold for the feature selection,
\item \code{method.fs} - method for the feature selection, may be
\code{AUC}, \code{FC}, or \code{Wilcoxon}
} See Details for more information.
Defaults to \code{list(thres.fs=100, method.fs="AUC")}}

\item{verbose}{control output: \code{0} for no output at all, \code{1}
for only information about progress and success, \code{2} for normal
level of information and \code{3} for full debug information,
defaults to \code{1}}
}
\value{
object of class \link{siamcat-class} with added \code{model_list}
}
\description{
This function trains the a machine learning model on the
    training data
}
\details{
This functions performs the training of the machine learning model
    and functions as an interface to the \code{mlr}-package.

    The function expects a \link{siamcat-class}-object with a prepared
    cross-validation (see \link{create.data.split}) in the
    \code{data_split}-slot of the object. It then trains a model for
    each fold of the datasplit.

    For the machine learning methods that require additional
    hyperparameters (e.g. \code{lasso_ll}), the optimal hyperparameters
    are tuned with the function \link[mlr]{tuneParams} within the
    \code{mlr}-package.

    The methods \code{'lasso'}, \code{'enet'}, and \code{'ridge'} are
    implemented as mlr-taks using the \code{'classif.cvglmnet'} Learner,
    \code{'lasso_ll'} and \code{'ridge_ll'} use the
    \code{'classif.LiblineaRL1LogReg'} and the
    \code{'classif.LiblineaRL2LogReg'} Learners respectively. The
    \code{'randomForest'} method is implemented via the
    \code{'classif.randomForest'} Learner.

    The function can also perform feature selection on each individual fold.
    At the moment, three methods for feature selection are implemented:
    \itemize{
    \item \code{'AUC'} computes the Area Under the Receiver Operating
        Characteristics Curve for each single feature and selects the top
        \code{param.fs$thres.fs}, e.g. 100 features
    \item \code{'FC'} computes the generalized Fold Change (see
        \link{check.associations}) for each feature and likewise selects the
        top \code{param.fs$thres.fs}, e.g. 100 features
    \item \code{Wilcoxon} computes the p-Value for each single feature with
        the Wilcoxon test and selects features with a p-Value smaller than
        \code{param.fs$thres.fs}
    }
}
\examples{

    data(siamcat_example)
    # simple working example
    siamcat_validated <- train.model(siamcat_example, method='lasso')

}
\keyword{SIAMCAT}
\keyword{plm.trainer}
